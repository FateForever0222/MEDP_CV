data:
  current_dataset: AQuA
  datasets:
  - name: CSQA
    path: data/raw/csqa
    type: commonsense
  - name: StrategyQA
    path: data/raw/strategyqa
    type: commonsense
  - name: Letter
    path: data/raw/letter
    type: symbolic
  - name: Coin
    path: data/raw/coin
    type: symbolic
  - name: MultiArith
    path: data/raw/multiarith
    type: mathematical
  - name: AQuA
    path: data/raw/aqua
    type: mathematical
  deduplication:
    algorithm: minhash
    similarity_threshold: 0.9
  expert_libraries:
    examples_per_expert: 80
    long_chain:
      prompt_template: Let's analyze this in detail step by step.
      step_range:
      - 7
      - 100
    medium_chain:
      prompt_template: Let's think step by step.
      step_range:
      - 4
      - 6
    path: data/expert_libraries
    short_chain:
      prompt_template: Let's think this through step by step, but keep it brief.
      step_range:
      - 1
      - 3
  processed_path: data/processed
  quality_filter:
    enabled: true
  raw_path: data/raw
evaluation:
  metrics:
  - accuracy
  - consistency
  - step_efficiency
  test_split_ratio: 0.2
experts:
  dropout: 0.1
  embedding_dim: 768
  hidden_dim: 512
gating:
  dropout: 0.2
  hidden_dims:
  - 768
  - 512
  - 256
  model_type: transformer
  temperature: 1.0
inference:
  confidence_threshold: 0.7
  max_retries: 3
  retry_strategies:
  - change_expert
  - adjust_prompt
  - increase_experts
llm:
  api_url: http://localhost:11434/api/generate
  max_tokens: 1024
  model_name: llama2:13B
  temperature: 0.0
  timeout: 30
logging:
  console_level: WARNING
  file_level: INFO
  level: INFO
  save_path: logs/
training:
  grpo:
    batch_size: 32
    early_stopping_patience: 3
    kl_coef: 0.2
    learning_rate: 0.0003
    max_epochs: 20
    noise_std: 0.1
    num_groups: 4
    samples_per_epoch: 50
  reward:
    accuracy_weight: 0.7
    confidence_weight: 0.2
    step_score_weight: 0.1
    use_non_linear: false
